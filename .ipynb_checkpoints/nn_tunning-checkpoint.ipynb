{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e76576b-8a46-4099-81cb-4f7895bd1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f528537-d01d-4b4e-864c-9f00ff15a6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.constraints import MaxNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0eb33-8e04-4226-919c-b7b99068bf30",
   "metadata": {},
   "source": [
    "<h1> Epoch and Batch Optimization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3726f168-4c6f-4c20-8656-2d161d895fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.705729 using {'epochs': 100, 'batch_size': 60}\n",
      "0.569010 (0.091573) with: {'epochs': 10, 'batch_size': 60}\n",
      "0.617188 (0.031894) with: {'epochs': 50, 'batch_size': 60}\n",
      "0.705729 (0.024360) with: {'epochs': 100, 'batch_size': 60}\n",
      "0.539062 (0.094775) with: {'epochs': 10, 'batch_size': 80}\n",
      "0.628906 (0.011500) with: {'epochs': 50, 'batch_size': 80}\n",
      "0.674479 (0.007366) with: {'epochs': 100, 'batch_size': 80}\n",
      "0.553385 (0.070192) with: {'epochs': 10, 'batch_size': 100}\n",
      "0.604167 (0.046146) with: {'epochs': 50, 'batch_size': 100}\n",
      "0.653646 (0.030647) with: {'epochs': 100, 'batch_size': 100}\n"
     ]
    }
   ],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "# load dataset\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51ebc0-0334-4b8e-8ca9-f6b72043a78f",
   "metadata": {},
   "source": [
    "<h3>Grid Search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96a45595-d53f-477d-987f-d39d2cace09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.657552 using {'batch_size': 80, 'epochs': 100}\n",
      "0.585938 (0.042910) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.627604 (0.006639) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.643229 (0.004872) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.561198 (0.044690) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.621094 (0.016573) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.657552 (0.018136) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.501302 (0.065156) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.601562 (0.008438) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.562500 (0.030758) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f41607-be1b-45a7-9c07-46d2e3fea9a4",
   "metadata": {},
   "source": [
    "<h3>Random Search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a29e0291-b106-452e-bfc3-a74894a88c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.694010 using {'epochs': 100, 'batch_size': 60}\n",
      "0.585938 (0.040720) with: {'epochs': 10, 'batch_size': 60}\n",
      "0.628906 (0.030425) with: {'epochs': 50, 'batch_size': 60}\n",
      "0.694010 (0.047343) with: {'epochs': 100, 'batch_size': 60}\n",
      "0.542969 (0.062744) with: {'epochs': 10, 'batch_size': 80}\n",
      "0.602865 (0.017566) with: {'epochs': 50, 'batch_size': 80}\n",
      "0.648438 (0.041707) with: {'epochs': 100, 'batch_size': 80}\n",
      "0.496094 (0.082925) with: {'epochs': 10, 'batch_size': 100}\n",
      "0.631510 (0.040133) with: {'epochs': 50, 'batch_size': 100}\n",
      "0.641927 (0.017566) with: {'epochs': 100, 'batch_size': 100}\n"
     ]
    }
   ],
   "source": [
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67764599-9e4f-4f87-98f8-aac62e8acee8",
   "metadata": {},
   "source": [
    "<h1> Optimization Alg. Tunning </1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f986a173-6d95-4f7b-b6a4-f2b3ef848e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    " model.add(Dense(1, activation='sigmoid'))\n",
    " # return model without compile\n",
    " return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acd6ee3e-b473-4e06-a53d-a4813b9bd76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "# load dataset\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, loss=\"binary_crossentropy\", epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51dc9c6a-6a91-456b-b634-1a85de9e6910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.718750 using {'optimizer': 'Nadam'}\n",
      "0.653646 (0.001841) with: {'optimizer': 'SGD'}\n",
      "0.694010 (0.017566) with: {'optimizer': 'RMSprop'}\n",
      "0.500000 (0.121701) with: {'optimizer': 'Adagrad'}\n",
      "0.424479 (0.100472) with: {'optimizer': 'Adadelta'}\n",
      "0.667969 (0.038670) with: {'optimizer': 'Adam'}\n",
      "0.622396 (0.028587) with: {'optimizer': 'Adamax'}\n",
      "0.718750 (0.020915) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107f57d-97a4-471a-bbd2-ba2dc6f2b5ad",
   "metadata": {},
   "source": [
    "<h1>Learning Rate Opt.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25011e52-28b0-4428-8802-c9f0b4455232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    " model.add(Dense(1, activation='sigmoid'))\n",
    " return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d99e735-9434-4548-8709-28943bd2a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "# load dataset\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, loss=\"binary_crossentropy\", optimizer=\"SGD\", epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "momentum = [0.2, 0.4, 0.6]\n",
    "param_grid = dict(optimizer__learning_rate=learn_rate, optimizer__momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "068a098e-1a45-4f02-8750-98bb721afc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.691406 using {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.2}\n",
      "0.691406 (0.011049) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.2}\n",
      "0.690104 (0.018414) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.4}\n",
      "0.670573 (0.020505) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.6}\n",
      "0.654948 (0.012075) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.2}\n",
      "0.649740 (0.003683) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.4}\n",
      "0.649740 (0.006639) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.6}\n",
      "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.2}\n",
      "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.4}\n",
      "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.6}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee7093-a025-4b45-a9ca-1f5db62adf90",
   "metadata": {},
   "source": [
    "<h1> Activation function opt. </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9ebe5c4-ddc1-4e28-b5b6-d182c92dad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation='relu'):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(12, input_shape=(8,), kernel_initializer='uniform', activation=activation))\n",
    " model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    " # Compile model\n",
    " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "524c6b29-e60d-4017-98e9-20baefab9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "# load dataset\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(model__activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50680966-3194-4635-a4ee-f9531799c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.734375 using {'model__activation': 'softplus'}\n",
      "0.658854 (0.008027) with: {'model__activation': 'softmax'}\n",
      "0.734375 (0.037603) with: {'model__activation': 'softplus'}\n",
      "0.671875 (0.003189) with: {'model__activation': 'softsign'}\n",
      "0.709635 (0.020505) with: {'model__activation': 'relu'}\n",
      "0.669271 (0.032578) with: {'model__activation': 'tanh'}\n",
      "0.692708 (0.027866) with: {'model__activation': 'sigmoid'}\n",
      "0.691406 (0.027621) with: {'model__activation': 'hard_sigmoid'}\n",
      "0.722656 (0.013902) with: {'model__activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcd06d-79be-4d18-9d0d-3366d404be41",
   "metadata": {},
   "source": [
    "<h1>Number of neurons</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d10e004-fce3-4738-9691-26f68af18029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(neurons, input_shape=(8,), kernel_initializer='uniform', activation='linear', kernel_constraint=MaxNorm(4)))\n",
    " #model.add(Dropout(0.2))\n",
    " model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    " # Compile model\n",
    " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05691c03-e26a-45f4-b782-712c15e8a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "# load dataset\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(model__neurons=neurons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "355b3fa1-569d-4df6-9356-742a3d3468ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.720052 using {'model__neurons': 10}\n",
      "0.704427 (0.008027) with: {'model__neurons': 1}\n",
      "0.716146 (0.003683) with: {'model__neurons': 5}\n",
      "0.720052 (0.007366) with: {'model__neurons': 10}\n",
      "0.720052 (0.010253) with: {'model__neurons': 15}\n",
      "0.716146 (0.018688) with: {'model__neurons': 20}\n",
      "0.713542 (0.015073) with: {'model__neurons': 25}\n",
      "0.713542 (0.018136) with: {'model__neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
